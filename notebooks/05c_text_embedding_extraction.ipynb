{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd439efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Using device: cpu\n",
      "SentenceTransformer model loaded.\n",
      "Starting text embedding generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdb7dc08b5447eb9ac077b50004cef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings generated with shape: (150000, 384)\n",
      "\n",
      " Text embedding features saved to: ../data/processed\\text_embeddings_v1.parquet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd, numpy as np, os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2' # A fast and powerful sentence transformer\n",
    "BATCH_SIZE = 64\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME, device=DEVICE)\n",
    "print(\"SentenceTransformer model loaded.\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"../data/raw/dataset/train.csv\"); test_df = pd.read_csv(\"../data/raw/dataset/test.csv\")\n",
    "full_df = pd.concat([train_df.assign(is_train=1), test_df.assign(is_train=0)], ignore_index=True)\n",
    "\n",
    "# Use the 'catalog_content' for embeddings\n",
    "texts_to_encode = full_df['catalog_content'].tolist()\n",
    "\n",
    "print(\"Starting text embedding generation...\")\n",
    "text_embeddings = model.encode(texts_to_encode, batch_size=BATCH_SIZE, show_progress_bar=True)\n",
    "print(f\"Text embeddings generated with shape: {text_embeddings.shape}\")\n",
    "\n",
    "embedding_cols = [f\"txt_emb_{i}\" for i in range(text_embeddings.shape[1])]\n",
    "text_features_df = pd.DataFrame(text_embeddings, columns=embedding_cols)\n",
    "\n",
    "PROCESSED_DIR = \"../data/processed\"; os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "SAVE_PATH = os.path.join(PROCESSED_DIR, \"text_embeddings_v1.parquet\")\n",
    "text_features_df.to_parquet(SAVE_PATH, index=False)\n",
    "print(f\"\\n Text embedding features saved to: {SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
